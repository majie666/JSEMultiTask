{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    返回census-income数据集\n",
    "    @param train_data:训练集特征\n",
    "    @param train_label:训练集标签\n",
    "    @param test_data:测试集特征\n",
    "    @param test_label:测试集标签\n",
    "    @param validation_data:验证集特征\n",
    "    @param validation_label:验证集标签\n",
    "'''\n",
    "def data_processing():\n",
    "    # 数据集列表名\n",
    "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
    "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
    "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
    "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
    "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
    "    #读取训练数据\n",
    "    train_df = pd.read_csv(\n",
    "        './dataset/census-income.data.gz',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    #读取测试数据\n",
    "    other_df = pd.read_csv(\n",
    "        './dataset/census-income.test',\n",
    "        delimiter=',',\n",
    "        header=None,\n",
    "        index_col=None,\n",
    "        names=column_names\n",
    "    )\n",
    "    # 特征名字\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    # First group of tasks according to the paper\n",
    "    label_columns = ['income_50k', 'marital_stat']\n",
    "\n",
    "    # One-hot encoding categorical columns\n",
    "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
    "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
    "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
    "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
    "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
    "                           'vet_question']\n",
    "    train_raw_labels = train_df[label_columns]\n",
    "    other_raw_labels = other_df[label_columns]\n",
    "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
    "    #print(transformed_train.columns.values)\n",
    "    #print(transformed_other.shape)\n",
    "    #print(transformed_train.shape)\n",
    "    \n",
    "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
    "    \n",
    "    #获得标签量，并根据要求转换为one-hot向量\n",
    "    train_income = keras.utils.to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    train_marital = keras.utils.to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    other_income = keras.utils.to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
    "    other_marital = keras.utils.to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
    "    \n",
    "    # 转换为字典\n",
    "    dict_outputs = {\n",
    "        'income': train_income.shape[1],\n",
    "        'marital': train_marital.shape[1]\n",
    "    }\n",
    "    dict_train_labels = {\n",
    "        'income': train_income,\n",
    "        'marital': train_marital\n",
    "    }\n",
    "    dict_other_labels = {\n",
    "        'income': other_income,\n",
    "        'marital': other_marital\n",
    "    }\n",
    "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
    "    \n",
    "    # 将测试集划分 为测试集和验证集 1:1的比例\n",
    "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=1).index\n",
    "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
    "    validation_data = transformed_other.iloc[validation_indices]\n",
    "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    test_data = transformed_other.iloc[test_indices]\n",
    "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
    "    train_data = transformed_train\n",
    "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    生成包含数据及标签的矩阵,因为在这里label是一个包含两个array的矩阵，因此需要有部分操作\n",
    "    @param data 数据集合\n",
    "    @param label 数据标签\n",
    "    \n",
    "    @return data 返回数据与数据集合一起的标签\n",
    "'''\n",
    "def generate_data(data, label):\n",
    "    for i in range(0, len(label)):\n",
    "        data = np.c_[data, label[i]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_label, val_data, val_label, test_data, test_label = data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_np = generate_data(train_data, train_label)\n",
    "test_data_np = generate_data(test_data, test_label)\n",
    "val_data_np = generate_data(val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = './dataset/generate_csv'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    @param output_dir 输出目录\n",
    "    @param data 输出数据\n",
    "    @param name_prefix 文件名前缀\n",
    "    @param header\n",
    "    @param n_parts 划分文件数大小\n",
    "    @return filenames 生成文件名list\n",
    "'''\n",
    "def save_to_csv(output_dir, data, name_prefix, header=None, n_parts=10):\n",
    "    path_format = os.path.join(output_dir, '{}_{:02d}.csv')\n",
    "    filenames = []\n",
    "    \n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(len(data)), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filenames.append(part_csv)\n",
    "        with open(part_csv, 'wt', encoding='utf-8') as f:\n",
    "            if header is not None:\n",
    "                f.write(header + '\\n')\n",
    "            for row_index in row_indices:\n",
    "                f.write(','.join([repr(col) for col in data[row_index]]))\n",
    "                f.write('\\n')\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/generate_csv\\\\train_data_00.csv',\n",
       " './dataset/generate_csv\\\\train_data_01.csv',\n",
       " './dataset/generate_csv\\\\train_data_02.csv',\n",
       " './dataset/generate_csv\\\\train_data_03.csv',\n",
       " './dataset/generate_csv\\\\train_data_04.csv',\n",
       " './dataset/generate_csv\\\\train_data_05.csv',\n",
       " './dataset/generate_csv\\\\train_data_06.csv',\n",
       " './dataset/generate_csv\\\\train_data_07.csv',\n",
       " './dataset/generate_csv\\\\train_data_08.csv',\n",
       " './dataset/generate_csv\\\\train_data_09.csv']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_to_csv(output_dir, train_data_np, 'train_data', None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/generate_csv\\\\val_data_00.csv',\n",
       " './dataset/generate_csv\\\\val_data_01.csv',\n",
       " './dataset/generate_csv\\\\val_data_02.csv',\n",
       " './dataset/generate_csv\\\\val_data_03.csv',\n",
       " './dataset/generate_csv\\\\val_data_04.csv',\n",
       " './dataset/generate_csv\\\\val_data_05.csv',\n",
       " './dataset/generate_csv\\\\val_data_06.csv',\n",
       " './dataset/generate_csv\\\\val_data_07.csv',\n",
       " './dataset/generate_csv\\\\val_data_08.csv',\n",
       " './dataset/generate_csv\\\\val_data_09.csv']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_to_csv(output_dir, test_data_np, 'test_data', None, 10)\n",
    "save_to_csv(output_dir, val_data_np, 'val_data', None,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
